Run 2 generated on 20250413_142507
Train script: /home/eddy/Documents/Agentomics-ML/datasets/competitors/1-shot_llm_agent/gpt4o/train_2.py
Inference script: /home/eddy/Documents/Agentomics-ML/datasets/competitors/1-shot_llm_agent/gpt4o/inference_2.py

Train execution on 2025-04-13 14:25:22
Command: python /home/eddy/Documents/Agentomics-ML/datasets/competitors/1-shot_llm_agent/gpt4o/train_2.py
Duration: 15.41 seconds
Return code: 0

STDOUT:
Epoch 1/10

[1m  1/678[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m15:24[0m 1s/step - AUC: 0.3922 - loss: 0.7115
[1m 57/678[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 902us/step - AUC: 0.7256 - loss: 0.6035
[1m 82/678[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 1ms/step - AUC: 0.7457 - loss: 0.5865  
[1m107/678[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 1ms/step - AUC: 0.7586 - loss: 0.5750
[1m125/678[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 2ms/step - AUC: 0.7664 - loss: 0.5676
[1m146/678[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 2ms/step - AUC: 0.7741 - loss: 0.5599
[1m164/678[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 2ms/step - AUC: 0.7800 - loss: 0.5536
[1m183/678[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 2ms/step - AUC: 0.7854 - loss: 0.5480
[1m200/678[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 2ms/step - AUC: 0.7897 - loss: 0.5434
[1m217/678[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 2ms/step - AUC: 0.7936 - loss: 0.5391
[1m278/678[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 2ms/step - AUC: 0.8055 - loss: 0.5258
[1m312/678[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 2ms/step - AUC: 0.8109 - loss: 0.5195
[1m338/678[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 2ms/step - AUC: 0.8146 - loss: 0.5150
[1m363/678[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 2ms/step - AUC: 0.8179 - loss: 0.5111
[1m405/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 2ms/step - AUC: 0.8227 - loss: 0.5051
[1m472/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 2ms/step - AUC: 0.8295 - loss: 0.4966
[1m532/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 2ms/step - AUC: 0.8345 - loss: 0.4901
[1m575/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 2ms/step - AUC: 0.8377 - loss: 0.4857
[1m612/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 2ms/step - AUC: 0.8403 - loss: 0.4822
[1m636/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 2ms/step - AUC: 0.8419 - loss: 0.4801
[1m656/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 2ms/step - AUC: 0.8431 - loss: 0.4783
[1m677/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 2ms/step - AUC: 0.8444 - loss: 0.4765
[1m678/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 2ms/step - AUC: 0.8445 - loss: 0.4765
[1m678/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m4s[0m 3ms/step - AUC: 0.8445 - loss: 0.4764 - val_AUC: 0.9230 - val_loss: 0.3503
Epoch 2/10

[1m  1/678[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m7s[0m 11ms/step - AUC: 0.9048 - loss: 0.3852
[1m 85/678[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 596us/step - AUC: 0.9226 - loss: 0.3466
[1m168/678[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 602us/step - AUC: 0.9204 - loss: 0.3496
[1m220/678[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 688us/step - AUC: 0.9205 - loss: 0.3491
[1m237/678[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 854us/step - AUC: 0.9208 - loss: 0.3485
[1m256/678[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 989us/step - AUC: 0.9210 - loss: 0.3479
[1m281/678[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 1ms/step - AUC: 0.9212 - loss: 0.3473  
[1m313/678[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 1ms/step - AUC: 0.9215 - loss: 0.3466
[1m378/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 1ms/step - AUC: 0.9222 - loss: 0.3451
[1m454/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 1ms/step - AUC: 0.9230 - loss: 0.3433
[1m531/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 954us/step - AUC: 0.9237 - loss: 0.3419
[1m601/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 926us/step - AUC: 0.9242 - loss: 0.3409
[1m673/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 902us/step - AUC: 0.9246 - loss: 0.3402
[1m678/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 1ms/step - AUC: 0.9246 - loss: 0.3401 - val_AUC: 0.9314 - val_loss: 0.3283
Epoch 3/10

[1m  1/678[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m7s[0m 10ms/step - AUC: 0.9405 - loss: 0.3167
[1m 60/678[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 864us/step - AUC: 0.9373 - loss: 0.3121
[1m 90/678[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 1ms/step - AUC: 0.9390 - loss: 0.3072  
[1m107/678[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 1ms/step - AUC: 0.9398 - loss: 0.3050
[1m137/678[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 1ms/step - AUC: 0.9405 - loss: 0.3029
[1m197/678[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 1ms/step - AUC: 0.9408 - loss: 0.3020
[1m249/678[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 1ms/step - AUC: 0.9410 - loss: 0.3014
[1m325/678[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 1ms/step - AUC: 0.9412 - loss: 0.3008
[1m361/678[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 1ms/step - AUC: 0.9413 - loss: 0.3006
[1m445/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 1ms/step - AUC: 0.9414 - loss: 0.3003
[1m532/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 951us/step - AUC: 0.9414 - loss: 0.3004
[1m619/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 899us/step - AUC: 0.9414 - loss: 0.3006
[1m678/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 1ms/step - AUC: 0.9413 - loss: 0.3008 - val_AUC: 0.9349 - val_loss: 0.3327
Epoch 4/10

[1m  1/678[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m7s[0m 11ms/step - AUC: 0.8826 - loss: 0.4583
[1m 88/678[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 575us/step - AUC: 0.9498 - loss: 0.2784
[1m170/678[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 594us/step - AUC: 0.9521 - loss: 0.2723
[1m259/678[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 584us/step - AUC: 0.9531 - loss: 0.2702
[1m348/678[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 579us/step - AUC: 0.9532 - loss: 0.2699
[1m430/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 585us/step - AUC: 0.9534 - loss: 0.2696
[1m512/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 590us/step - AUC: 0.9533 - loss: 0.2698
[1m598/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 589us/step - AUC: 0.9531 - loss: 0.2704
[1m678/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 749us/step - AUC: 0.9529 - loss: 0.2711 - val_AUC: 0.9346 - val_loss: 0.3196
Epoch 5/10

[1m  1/678[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m7s[0m 10ms/step - AUC: 0.9785 - loss: 0.2042
[1m 64/678[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 796us/step - AUC: 0.9652 - loss: 0.2393
[1m113/678[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 895us/step - AUC: 0.9642 - loss: 0.2420
[1m187/678[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 810us/step - AUC: 0.9630 - loss: 0.2454
[1m239/678[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 843us/step - AUC: 0.9627 - loss: 0.2461
[1m299/678[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 843us/step - AUC: 0.9622 - loss: 0.2472
[1m360/678[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 840us/step - AUC: 0.9616 - loss: 0.2488
[1m437/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 807us/step - AUC: 0.9610 - loss: 0.2503
[1m517/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 779us/step - AUC: 0.9606 - loss: 0.2511
[1m594/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 763us/step - AUC: 0.9603 - loss: 0.2518
[1m674/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 748us/step - AUC: 0.9600 - loss: 0.2525
[1m678/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 1ms/step - AUC: 0.9600 - loss: 0.2526 - val_AUC: 0.9345 - val_loss: 0.3394
Epoch 6/10

[1m  1/678[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m7s[0m 11ms/step - AUC: 0.9555 - loss: 0.2903
[1m 66/678[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 783us/step - AUC: 0.9646 - loss: 0.2384
[1m107/678[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 968us/step - AUC: 0.9671 - loss: 0.2299
[1m129/678[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 1ms/step - AUC: 0.9675 - loss: 0.2284  
[1m146/678[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 1ms/step - AUC: 0.9678 - loss: 0.2274
[1m190/678[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 1ms/step - AUC: 0.9681 - loss: 0.2261
[1m214/678[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 1ms/step - AUC: 0.9681 - loss: 0.2259
[1m233/678[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 2ms/step - AUC: 0.9681 - loss: 0.2257
[1m250/678[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 2ms/step - AUC: 0.9680 - loss: 0.2258
[1m274/678[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 2ms/step - AUC: 0.9680 - loss: 0.2259
[1m289/678[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 2ms/step - AUC: 0.9679 - loss: 0.2261
[1m314/678[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 2ms/step - AUC: 0.9679 - loss: 0.2263
[1m356/678[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 2ms/step - AUC: 0.9678 - loss: 0.2265
[1m373/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 2ms/step - AUC: 0.9678 - loss: 0.2266
[1m388/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 2ms/step - AUC: 0.9678 - loss: 0.2267
[1m405/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 2ms/step - AUC: 0.9677 - loss: 0.2269
[1m425/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 2ms/step - AUC: 0.9677 - loss: 0.2272
[1m499/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 2ms/step - AUC: 0.9675 - loss: 0.2279
[1m574/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 2ms/step - AUC: 0.9673 - loss: 0.2285
[1m638/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 2ms/step - AUC: 0.9672 - loss: 0.2288
[1m666/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 2ms/step - AUC: 0.9672 - loss: 0.2288
[1m678/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 2ms/step - AUC: 0.9672 - loss: 0.2289 - val_AUC: 0.9342 - val_loss: 0.3455
Epoch 7/10

[1m  1/678[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m7s[0m 11ms/step - AUC: 0.9879 - loss: 0.1709
[1m 58/678[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 897us/step - AUC: 0.9834 - loss: 0.1713
[1m110/678[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 932us/step - AUC: 0.9822 - loss: 0.1751
[1m132/678[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 1ms/step - AUC: 0.9819 - loss: 0.1765  
[1m150/678[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 1ms/step - AUC: 0.9816 - loss: 0.1775
[1m203/678[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 1ms/step - AUC: 0.9810 - loss: 0.1796
[1m286/678[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 1ms/step - AUC: 0.9805 - loss: 0.1814
[1m339/678[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 1ms/step - AUC: 0.9801 - loss: 0.1829
[1m358/678[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 1ms/step - AUC: 0.9799 - loss: 0.1835
[1m439/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 1ms/step - AUC: 0.9792 - loss: 0.1858
[1m491/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 1ms/step - AUC: 0.9789 - loss: 0.1871
[1m517/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 1ms/step - AUC: 0.9787 - loss: 0.1877
[1m538/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 1ms/step - AUC: 0.9786 - loss: 0.1882
[1m576/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 1ms/step - AUC: 0.9783 - loss: 0.1890
[1m599/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 1ms/step - AUC: 0.9782 - loss: 0.1894
[1m625/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 1ms/step - AUC: 0.9781 - loss: 0.1898
[1m674/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 1ms/step - AUC: 0.9778 - loss: 0.1906
[1m678/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 1ms/step - AUC: 0.9778 - loss: 0.1906 - val_AUC: 0.9264 - val_loss: 0.3672
Epoch 8/10

[1m  1/678[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m7s[0m 11ms/step - AUC: 0.9921 - loss: 0.1373
[1m 83/678[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 611us/step - AUC: 0.9850 - loss: 0.1672
[1m166/678[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 608us/step - AUC: 0.9852 - loss: 0.1627
[1m248/678[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 609us/step - AUC: 0.9854 - loss: 0.1601
[1m323/678[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 623us/step - AUC: 0.9855 - loss: 0.1591
[1m403/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 624us/step - AUC: 0.9855 - loss: 0.1583
[1m480/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 628us/step - AUC: 0.9855 - loss: 0.1581
[1m525/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 671us/step - AUC: 0.9854 - loss: 0.1581
[1m547/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 738us/step - AUC: 0.9854 - loss: 0.1581
[1m564/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 804us/step - AUC: 0.9854 - loss: 0.1581
[1m583/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 866us/step - AUC: 0.9853 - loss: 0.1582
[1m632/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 879us/step - AUC: 0.9853 - loss: 0.1583
[1m666/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 911us/step - AUC: 0.9852 - loss: 0.1585
[1m678/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 1ms/step - AUC: 0.9852 - loss: 0.1586 - val_AUC: 0.9271 - val_loss: 0.3965
Epoch 9/10

[1m  1/678[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m9s[0m 15ms/step - AUC: 1.0000 - loss: 0.0828
[1m 42/678[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 1ms/step - AUC: 0.9963 - loss: 0.0981 
[1m 58/678[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 2ms/step - AUC: 0.9955 - loss: 0.1017
[1m 76/678[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 2ms/step - AUC: 0.9949 - loss: 0.1040
[1m104/678[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 2ms/step - AUC: 0.9944 - loss: 0.1066
[1m159/678[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 2ms/step - AUC: 0.9937 - loss: 0.1101
[1m182/678[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 2ms/step - AUC: 0.9936 - loss: 0.1108
[1m200/678[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 2ms/step - AUC: 0.9935 - loss: 0.1111
[1m229/678[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 2ms/step - AUC: 0.9934 - loss: 0.1115
[1m247/678[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 2ms/step - AUC: 0.9934 - loss: 0.1118
[1m266/678[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 2ms/step - AUC: 0.9933 - loss: 0.1121
[1m343/678[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 2ms/step - AUC: 0.9930 - loss: 0.1135
[1m395/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 2ms/step - AUC: 0.9928 - loss: 0.1143
[1m421/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 2ms/step - AUC: 0.9927 - loss: 0.1148
[1m438/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 2ms/step - AUC: 0.9927 - loss: 0.1151
[1m476/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 2ms/step - AUC: 0.9926 - loss: 0.1157
[1m525/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 2ms/step - AUC: 0.9924 - loss: 0.1165
[1m611/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 1ms/step - AUC: 0.9921 - loss: 0.1179
[1m667/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 1ms/step - AUC: 0.9920 - loss: 0.1187
[1m678/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 2ms/step - AUC: 0.9919 - loss: 0.1189 - val_AUC: 0.9185 - val_loss: 0.4345
Epoch 10/10

[1m  1/678[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m7s[0m 11ms/step - AUC: 1.0000 - loss: 0.0542
[1m 80/678[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 637us/step - AUC: 0.9971 - loss: 0.0820
[1m159/678[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 635us/step - AUC: 0.9966 - loss: 0.0852
[1m239/678[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 632us/step - AUC: 0.9964 - loss: 0.0853
[1m319/678[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 631us/step - AUC: 0.9965 - loss: 0.0844
[1m399/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 630us/step - AUC: 0.9965 - loss: 0.0840
[1m479/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 630us/step - AUC: 0.9964 - loss: 0.0839
[1m509/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 693us/step - AUC: 0.9964 - loss: 0.0838
[1m534/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 755us/step - AUC: 0.9964 - loss: 0.0838
[1m554/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 818us/step - AUC: 0.9964 - loss: 0.0838
[1m574/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 879us/step - AUC: 0.9964 - loss: 0.0838
[1m590/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 941us/step - AUC: 0.9964 - loss: 0.0838
[1m608/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 998us/step - AUC: 0.9964 - loss: 0.0838
[1m632/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 1ms/step - AUC: 0.9963 - loss: 0.0838  
[1m673/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 1ms/step - AUC: 0.9963 - loss: 0.0839
[1m678/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 1ms/step - AUC: 0.9963 - loss: 0.0840 - val_AUC: 0.9200 - val_loss: 0.5148

STDERR:
2025-04-13 14:25:07.534977: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-04-13 14:25:07.541233: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-04-13 14:25:07.548830: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2025-04-13 14:25:07.551077: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-04-13 14:25:07.556703: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
/home/eddy/miniconda3/envs/s/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.
  super().__init__(activity_regularizer=activity_regularizer, **kwargs)
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1744547110.076532   45758 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
I0000 00:00:1744547110.096853   45758 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
I0000 00:00:1744547110.096969   45758 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
I0000 00:00:1744547110.097875   45758 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
I0000 00:00:1744547110.097944   45758 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
I0000 00:00:1744547110.097992   45758 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
I0000 00:00:1744547110.136731   45758 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
I0000 00:00:1744547110.136812   45758 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
I0000 00:00:1744547110.136870   45758 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-04-13 14:25:10.136917: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 8862 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070, pci bus id: 0000:01:00.0, compute capability: 8.9
I0000 00:00:1744547111.025940   45851 service.cc:146] XLA service 0x72f9380045a0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
I0000 00:00:1744547111.025954   45851 service.cc:154]   StreamExecutor device (0): NVIDIA GeForce RTX 4070, Compute Capability 8.9
2025-04-13 14:25:11.040668: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2025-04-13 14:25:11.100782: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 90100
I0000 00:00:1744547112.004075   45851 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. 

Inference execution on 2025-04-13 14:25:25
Command: python /home/eddy/Documents/Agentomics-ML/datasets/competitors/1-shot_llm_agent/gpt4o/inference_2.py --input /home/eddy/Documents/Agentomics-ML/datasets/human_non_tata_promoters/human_nontata_promoters_test.no_label.csv --output /home/eddy/Documents/Agentomics-ML/datasets/competitors/1-shot_llm_agent/gpt4o/predictions.csv
Duration: 3.35 seconds
Return code: 0

STDOUT:

[1m  1/283[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1:06[0m 235ms/step
[1m 75/283[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 687us/step  
[1m113/283[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 903us/step
[1m159/283[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 960us/step
[1m204/283[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 995us/step
[1m283/283[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 1ms/step  
[1m283/283[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 1ms/step

STDERR:
2025-04-13 14:25:22.930368: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-04-13 14:25:22.936457: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-04-13 14:25:22.943934: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2025-04-13 14:25:22.946316: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-04-13 14:25:22.951557: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1744547123.998085   47048 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
I0000 00:00:1744547124.020704   47048 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
I0000 00:00:1744547124.020811   47048 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
I0000 00:00:1744547124.021957   47048 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
I0000 00:00:1744547124.022037   47048 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
I0000 00:00:1744547124.022084   47048 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
I0000 00:00:1744547124.055137   47048 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
I0000 00:00:1744547124.055229   47048 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
I0000 00:00:1744547124.055287   47048 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-04-13 14:25:24.055334: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 8860 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070, pci bus id: 0000:01:00.0, compute capability: 8.9
WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
I0000 00:00:1744547125.041820   47128 service.cc:146] XLA service 0x7d83bc003810 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
I0000 00:00:1744547125.041840   47128 service.cc:154]   StreamExecutor device (0): NVIDIA GeForce RTX 4070, Compute Capability 8.9
2025-04-13 14:25:25.046504: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2025-04-13 14:25:25.053757: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 90100
I0000 00:00:1744547125.241300   47128 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.

Evaluation execution on 2025-04-13 14:25:26
Command: python /home/eddy/Documents/Agentomics-ML/src/eval/evaluate_result.py --results /home/eddy/Documents/Agentomics-ML/datasets/competitors/1-shot_llm_agent/gpt4o/predictions.csv --test /home/eddy/Documents/Agentomics-ML/datasets/human_non_tata_promoters/human_nontata_promoters_test.csv --output /home/eddy/Documents/Agentomics-ML/datasets/competitors/1-shot_llm_agent/gpt4o/metrics_run_2.txt
Duration: 0.42 seconds
Return code: 0

STDOUT:

STDERR:
