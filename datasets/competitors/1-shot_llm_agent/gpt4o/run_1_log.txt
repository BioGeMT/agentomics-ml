Run 1 generated on 20250413_142209
Train script: /home/eddy/Documents/Agentomics-ML/datasets/competitors/1-shot_llm_agent/gpt4o/train_1.py
Inference script: /home/eddy/Documents/Agentomics-ML/datasets/competitors/1-shot_llm_agent/gpt4o/inference_1.py

Train execution on 2025-04-13 14:22:27
Command: python /home/eddy/Documents/Agentomics-ML/datasets/competitors/1-shot_llm_agent/gpt4o/train_1.py
Duration: 18.62 seconds
Return code: 0

STDOUT:
Epoch 1/10

[1m  1/678[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m21:36[0m 2s/step - accuracy: 0.5938 - loss: 0.6795
[1m 24/678[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 2ms/step - accuracy: 0.5772 - loss: 0.7117  
[1m 41/678[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 3ms/step - accuracy: 0.6059 - loss: 0.6817
[1m 57/678[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 3ms/step - accuracy: 0.6238 - loss: 0.6639
[1m 74/678[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 3ms/step - accuracy: 0.6392 - loss: 0.6473
[1m 91/678[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 3ms/step - accuracy: 0.6507 - loss: 0.6350
[1m109/678[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 3ms/step - accuracy: 0.6602 - loss: 0.6243
[1m167/678[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 2ms/step - accuracy: 0.6823 - loss: 0.5984
[1m201/678[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 2ms/step - accuracy: 0.6912 - loss: 0.5875
[1m218/678[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 2ms/step - accuracy: 0.6950 - loss: 0.5827
[1m243/678[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 2ms/step - accuracy: 0.6997 - loss: 0.5766
[1m292/678[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 2ms/step - accuracy: 0.7074 - loss: 0.5665
[1m331/678[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 2ms/step - accuracy: 0.7124 - loss: 0.5598
[1m369/678[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 2ms/step - accuracy: 0.7167 - loss: 0.5539
[1m395/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 2ms/step - accuracy: 0.7195 - loss: 0.5502
[1m412/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 2ms/step - accuracy: 0.7212 - loss: 0.5479
[1m446/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 2ms/step - accuracy: 0.7242 - loss: 0.5436
[1m467/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 2ms/step - accuracy: 0.7260 - loss: 0.5412
[1m520/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 2ms/step - accuracy: 0.7300 - loss: 0.5356
[1m573/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 2ms/step - accuracy: 0.7336 - loss: 0.5304
[1m603/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 2ms/step - accuracy: 0.7355 - loss: 0.5276
[1m621/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 2ms/step - accuracy: 0.7366 - loss: 0.5261
[1m636/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 2ms/step - accuracy: 0.7375 - loss: 0.5248
[1m652/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 2ms/step - accuracy: 0.7384 - loss: 0.5234
[1m670/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 2ms/step - accuracy: 0.7394 - loss: 0.5219
[1m678/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 3ms/step - accuracy: 0.7399 - loss: 0.5213
[1m678/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m5s[0m 4ms/step - accuracy: 0.7400 - loss: 0.5212 - val_accuracy: 0.8173 - val_loss: 0.3909
Epoch 2/10

[1m  1/678[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m7s[0m 11ms/step - accuracy: 0.9375 - loss: 0.3373
[1m 74/678[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 691us/step - accuracy: 0.8384 - loss: 0.3883
[1m130/678[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 787us/step - accuracy: 0.8346 - loss: 0.3904
[1m194/678[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 787us/step - accuracy: 0.8322 - loss: 0.3912
[1m237/678[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 869us/step - accuracy: 0.8315 - loss: 0.3904
[1m252/678[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 1ms/step - accuracy: 0.8313 - loss: 0.3903  
[1m268/678[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 1ms/step - accuracy: 0.8310 - loss: 0.3903
[1m301/678[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 1ms/step - accuracy: 0.8306 - loss: 0.3901
[1m322/678[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 1ms/step - accuracy: 0.8304 - loss: 0.3900
[1m341/678[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 1ms/step - accuracy: 0.8301 - loss: 0.3899
[1m357/678[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 1ms/step - accuracy: 0.8299 - loss: 0.3899
[1m412/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 1ms/step - accuracy: 0.8295 - loss: 0.3897
[1m442/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 1ms/step - accuracy: 0.8294 - loss: 0.3894
[1m458/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 1ms/step - accuracy: 0.8294 - loss: 0.3892
[1m475/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 2ms/step - accuracy: 0.8294 - loss: 0.3890
[1m496/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 2ms/step - accuracy: 0.8293 - loss: 0.3889
[1m542/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 2ms/step - accuracy: 0.8291 - loss: 0.3885
[1m560/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 2ms/step - accuracy: 0.8291 - loss: 0.3885
[1m578/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 2ms/step - accuracy: 0.8290 - loss: 0.3884
[1m595/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 2ms/step - accuracy: 0.8289 - loss: 0.3883
[1m620/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 2ms/step - accuracy: 0.8289 - loss: 0.3882
[1m634/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 2ms/step - accuracy: 0.8289 - loss: 0.3881
[1m653/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 2ms/step - accuracy: 0.8289 - loss: 0.3880
[1m677/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 2ms/step - accuracy: 0.8288 - loss: 0.3879
[1m678/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 2ms/step - accuracy: 0.8288 - loss: 0.3879 - val_accuracy: 0.8456 - val_loss: 0.3559
Epoch 3/10

[1m  1/678[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m7s[0m 11ms/step - accuracy: 0.9062 - loss: 0.2709
[1m 34/678[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 2ms/step - accuracy: 0.8320 - loss: 0.3535 
[1m 53/678[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 2ms/step - accuracy: 0.8330 - loss: 0.3516
[1m100/678[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 2ms/step - accuracy: 0.8349 - loss: 0.3526
[1m133/678[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 2ms/step - accuracy: 0.8344 - loss: 0.3553
[1m148/678[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 2ms/step - accuracy: 0.8342 - loss: 0.3561
[1m164/678[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 2ms/step - accuracy: 0.8343 - loss: 0.3565
[1m180/678[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 2ms/step - accuracy: 0.8344 - loss: 0.3571
[1m199/678[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 2ms/step - accuracy: 0.8343 - loss: 0.3579
[1m213/678[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 2ms/step - accuracy: 0.8343 - loss: 0.3584
[1m243/678[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 2ms/step - accuracy: 0.8344 - loss: 0.3589
[1m297/678[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 2ms/step - accuracy: 0.8348 - loss: 0.3594
[1m363/678[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 2ms/step - accuracy: 0.8349 - loss: 0.3603
[1m408/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 2ms/step - accuracy: 0.8351 - loss: 0.3605
[1m451/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 2ms/step - accuracy: 0.8353 - loss: 0.3606
[1m482/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 2ms/step - accuracy: 0.8355 - loss: 0.3605
[1m496/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 2ms/step - accuracy: 0.8356 - loss: 0.3604
[1m515/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 2ms/step - accuracy: 0.8357 - loss: 0.3604
[1m533/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 2ms/step - accuracy: 0.8359 - loss: 0.3603
[1m547/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 2ms/step - accuracy: 0.8360 - loss: 0.3603
[1m580/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 2ms/step - accuracy: 0.8363 - loss: 0.3601
[1m596/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 2ms/step - accuracy: 0.8364 - loss: 0.3601
[1m612/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 2ms/step - accuracy: 0.8365 - loss: 0.3601
[1m654/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 2ms/step - accuracy: 0.8367 - loss: 0.3600
[1m678/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 2ms/step - accuracy: 0.8368 - loss: 0.3600 - val_accuracy: 0.8572 - val_loss: 0.3404
Epoch 4/10

[1m  1/678[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m7s[0m 11ms/step - accuracy: 0.9375 - loss: 0.2994
[1m 39/678[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 1ms/step - accuracy: 0.8338 - loss: 0.3574 
[1m 54/678[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 2ms/step - accuracy: 0.8362 - loss: 0.3556
[1m 70/678[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 2ms/step - accuracy: 0.8379 - loss: 0.3539
[1m 85/678[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 2ms/step - accuracy: 0.8394 - loss: 0.3520
[1m102/678[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 3ms/step - accuracy: 0.8407 - loss: 0.3500
[1m117/678[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 3ms/step - accuracy: 0.8418 - loss: 0.3489
[1m135/678[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 3ms/step - accuracy: 0.8428 - loss: 0.3482
[1m150/678[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 3ms/step - accuracy: 0.8435 - loss: 0.3475
[1m170/678[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 3ms/step - accuracy: 0.8443 - loss: 0.3468
[1m184/678[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 3ms/step - accuracy: 0.8449 - loss: 0.3463
[1m198/678[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 3ms/step - accuracy: 0.8454 - loss: 0.3458
[1m212/678[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 3ms/step - accuracy: 0.8460 - loss: 0.3451
[1m228/678[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 3ms/step - accuracy: 0.8465 - loss: 0.3445
[1m245/678[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 3ms/step - accuracy: 0.8470 - loss: 0.3439
[1m261/678[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 3ms/step - accuracy: 0.8475 - loss: 0.3435
[1m278/678[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 3ms/step - accuracy: 0.8479 - loss: 0.3430
[1m301/678[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 3ms/step - accuracy: 0.8483 - loss: 0.3426
[1m320/678[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 3ms/step - accuracy: 0.8486 - loss: 0.3421
[1m358/678[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 3ms/step - accuracy: 0.8491 - loss: 0.3413
[1m380/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 3ms/step - accuracy: 0.8493 - loss: 0.3409
[1m392/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 3ms/step - accuracy: 0.8494 - loss: 0.3407
[1m406/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 3ms/step - accuracy: 0.8496 - loss: 0.3405
[1m453/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 3ms/step - accuracy: 0.8498 - loss: 0.3402
[1m523/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 2ms/step - accuracy: 0.8501 - loss: 0.3400
[1m595/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 2ms/step - accuracy: 0.8503 - loss: 0.3399
[1m667/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 2ms/step - accuracy: 0.8503 - loss: 0.3400
[1m678/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 2ms/step - accuracy: 0.8503 - loss: 0.3400 - val_accuracy: 0.8526 - val_loss: 0.3302
Epoch 5/10

[1m  1/678[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m7s[0m 10ms/step - accuracy: 0.9375 - loss: 0.1414
[1m 35/678[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 2ms/step - accuracy: 0.8837 - loss: 0.2655 
[1m 53/678[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 2ms/step - accuracy: 0.8781 - loss: 0.2794
[1m 68/678[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 2ms/step - accuracy: 0.8755 - loss: 0.2862
[1m 89/678[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 2ms/step - accuracy: 0.8729 - loss: 0.2935
[1m106/678[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 2ms/step - accuracy: 0.8708 - loss: 0.2981
[1m141/678[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 2ms/step - accuracy: 0.8678 - loss: 0.3041
[1m211/678[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 2ms/step - accuracy: 0.8653 - loss: 0.3097
[1m281/678[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 1ms/step - accuracy: 0.8641 - loss: 0.3134
[1m350/678[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 1ms/step - accuracy: 0.8637 - loss: 0.3150
[1m421/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 1ms/step - accuracy: 0.8631 - loss: 0.3165
[1m491/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 1ms/step - accuracy: 0.8625 - loss: 0.3178
[1m562/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 1ms/step - accuracy: 0.8620 - loss: 0.3190
[1m635/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 1ms/step - accuracy: 0.8616 - loss: 0.3200
[1m678/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 1ms/step - accuracy: 0.8613 - loss: 0.3206 - val_accuracy: 0.8720 - val_loss: 0.3121
Epoch 6/10

[1m  1/678[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m7s[0m 10ms/step - accuracy: 0.8125 - loss: 0.3468
[1m 33/678[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 2ms/step - accuracy: 0.8576 - loss: 0.3120 
[1m 48/678[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 2ms/step - accuracy: 0.8606 - loss: 0.3111
[1m 92/678[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 2ms/step - accuracy: 0.8624 - loss: 0.3122
[1m118/678[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 2ms/step - accuracy: 0.8627 - loss: 0.3127
[1m135/678[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 2ms/step - accuracy: 0.8628 - loss: 0.3131
[1m151/678[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 2ms/step - accuracy: 0.8629 - loss: 0.3132
[1m165/678[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 2ms/step - accuracy: 0.8631 - loss: 0.3131
[1m180/678[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 2ms/step - accuracy: 0.8634 - loss: 0.3130
[1m194/678[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 2ms/step - accuracy: 0.8636 - loss: 0.3128
[1m214/678[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 2ms/step - accuracy: 0.8638 - loss: 0.3128
[1m273/678[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 2ms/step - accuracy: 0.8639 - loss: 0.3129
[1m298/678[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 2ms/step - accuracy: 0.8641 - loss: 0.3128
[1m311/678[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 2ms/step - accuracy: 0.8641 - loss: 0.3128
[1m326/678[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 2ms/step - accuracy: 0.8642 - loss: 0.3128
[1m340/678[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 2ms/step - accuracy: 0.8642 - loss: 0.3128
[1m381/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 2ms/step - accuracy: 0.8643 - loss: 0.3130
[1m406/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 2ms/step - accuracy: 0.8644 - loss: 0.3131
[1m473/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 2ms/step - accuracy: 0.8644 - loss: 0.3134
[1m510/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 2ms/step - accuracy: 0.8644 - loss: 0.3137
[1m538/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 2ms/step - accuracy: 0.8644 - loss: 0.3138
[1m569/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 2ms/step - accuracy: 0.8645 - loss: 0.3139
[1m603/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 2ms/step - accuracy: 0.8646 - loss: 0.3140
[1m655/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 2ms/step - accuracy: 0.8646 - loss: 0.3140
[1m678/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 2ms/step - accuracy: 0.8647 - loss: 0.3141 - val_accuracy: 0.8662 - val_loss: 0.3158
Epoch 7/10

[1m  1/678[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m7s[0m 11ms/step - accuracy: 1.0000 - loss: 0.1168
[1m 40/678[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 1ms/step - accuracy: 0.8832 - loss: 0.2940 
[1m 65/678[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 2ms/step - accuracy: 0.8790 - loss: 0.2993
[1m112/678[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 1ms/step - accuracy: 0.8766 - loss: 0.3001
[1m144/678[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 1ms/step - accuracy: 0.8749 - loss: 0.3018
[1m194/678[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 1ms/step - accuracy: 0.8734 - loss: 0.3032
[1m228/678[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 1ms/step - accuracy: 0.8725 - loss: 0.3042
[1m267/678[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 1ms/step - accuracy: 0.8717 - loss: 0.3050
[1m337/678[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 1ms/step - accuracy: 0.8708 - loss: 0.3058
[1m384/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 1ms/step - accuracy: 0.8705 - loss: 0.3057
[1m414/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 1ms/step - accuracy: 0.8703 - loss: 0.3057
[1m430/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 1ms/step - accuracy: 0.8702 - loss: 0.3057
[1m456/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 1ms/step - accuracy: 0.8701 - loss: 0.3056
[1m525/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 1ms/step - accuracy: 0.8698 - loss: 0.3056
[1m587/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 1ms/step - accuracy: 0.8695 - loss: 0.3058
[1m641/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 1ms/step - accuracy: 0.8693 - loss: 0.3060
[1m678/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 1ms/step - accuracy: 0.8691 - loss: 0.3061 - val_accuracy: 0.8664 - val_loss: 0.3140
Epoch 8/10

[1m  1/678[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m7s[0m 11ms/step - accuracy: 0.8438 - loss: 0.5235
[1m 58/678[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 899us/step - accuracy: 0.8850 - loss: 0.2927
[1m110/678[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 937us/step - accuracy: 0.8853 - loss: 0.2870
[1m130/678[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 1ms/step - accuracy: 0.8854 - loss: 0.2863  
[1m152/678[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 1ms/step - accuracy: 0.8850 - loss: 0.2866
[1m178/678[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 1ms/step - accuracy: 0.8846 - loss: 0.2866
[1m195/678[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 2ms/step - accuracy: 0.8843 - loss: 0.2868
[1m217/678[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 2ms/step - accuracy: 0.8839 - loss: 0.2871
[1m274/678[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 1ms/step - accuracy: 0.8822 - loss: 0.2882
[1m335/678[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 1ms/step - accuracy: 0.8804 - loss: 0.2898
[1m362/678[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 1ms/step - accuracy: 0.8798 - loss: 0.2904
[1m377/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 1ms/step - accuracy: 0.8795 - loss: 0.2907
[1m429/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 1ms/step - accuracy: 0.8788 - loss: 0.2913
[1m483/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 1ms/step - accuracy: 0.8781 - loss: 0.2919
[1m512/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 1ms/step - accuracy: 0.8777 - loss: 0.2922
[1m571/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 1ms/step - accuracy: 0.8772 - loss: 0.2927
[1m618/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 1ms/step - accuracy: 0.8768 - loss: 0.2932
[1m648/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 1ms/step - accuracy: 0.8765 - loss: 0.2934
[1m662/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 1ms/step - accuracy: 0.8764 - loss: 0.2935
[1m677/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 1ms/step - accuracy: 0.8763 - loss: 0.2936
[1m678/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 2ms/step - accuracy: 0.8763 - loss: 0.2936 - val_accuracy: 0.8740 - val_loss: 0.3014
Epoch 9/10

[1m  1/678[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m7s[0m 11ms/step - accuracy: 0.8125 - loss: 0.3553
[1m 53/678[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 971us/step - accuracy: 0.8751 - loss: 0.2968
[1m 92/678[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 1ms/step - accuracy: 0.8705 - loss: 0.3030  
[1m141/678[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 1ms/step - accuracy: 0.8689 - loss: 0.3027
[1m185/678[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 1ms/step - accuracy: 0.8696 - loss: 0.3007
[1m204/678[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 1ms/step - accuracy: 0.8700 - loss: 0.2997
[1m227/678[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 1ms/step - accuracy: 0.8705 - loss: 0.2990
[1m281/678[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 1ms/step - accuracy: 0.8716 - loss: 0.2973
[1m298/678[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 1ms/step - accuracy: 0.8720 - loss: 0.2968
[1m311/678[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 1ms/step - accuracy: 0.8723 - loss: 0.2963
[1m329/678[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 2ms/step - accuracy: 0.8726 - loss: 0.2958
[1m356/678[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 2ms/step - accuracy: 0.8730 - loss: 0.2952
[1m385/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 2ms/step - accuracy: 0.8734 - loss: 0.2947
[1m434/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 2ms/step - accuracy: 0.8740 - loss: 0.2940
[1m484/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 1ms/step - accuracy: 0.8743 - loss: 0.2934
[1m546/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 1ms/step - accuracy: 0.8746 - loss: 0.2931
[1m607/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 1ms/step - accuracy: 0.8747 - loss: 0.2931
[1m656/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 1ms/step - accuracy: 0.8747 - loss: 0.2931
[1m678/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 2ms/step - accuracy: 0.8748 - loss: 0.2930 - val_accuracy: 0.8601 - val_loss: 0.3152
Epoch 10/10

[1m  1/678[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m7s[0m 11ms/step - accuracy: 0.8438 - loss: 0.3322
[1m 63/678[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 819us/step - accuracy: 0.8602 - loss: 0.2937
[1m115/678[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 892us/step - accuracy: 0.8668 - loss: 0.2907
[1m149/678[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 1ms/step - accuracy: 0.8688 - loss: 0.2907  
[1m175/678[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 1ms/step - accuracy: 0.8702 - loss: 0.2908
[1m245/678[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 1ms/step - accuracy: 0.8734 - loss: 0.2900
[1m316/678[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 964us/step - accuracy: 0.8753 - loss: 0.2893
[1m387/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 919us/step - accuracy: 0.8765 - loss: 0.2882
[1m460/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 882us/step - accuracy: 0.8771 - loss: 0.2873
[1m530/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 860us/step - accuracy: 0.8776 - loss: 0.2864
[1m605/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 836us/step - accuracy: 0.8782 - loss: 0.2856
[1m678/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 820us/step - accuracy: 0.8787 - loss: 0.2849
[1m678/678[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 1ms/step - accuracy: 0.8787 - loss: 0.2848 - val_accuracy: 0.8683 - val_loss: 0.3063

[1m  1/170[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m17s[0m 102ms/step
[1m 43/170[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 1ms/step   
[1m143/170[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 711us/step
[1m170/170[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 1ms/step  
[1m170/170[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 1ms/step
Validation AUC: 0.9406

STDERR:
2025-04-13 14:22:09.513690: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-04-13 14:22:09.519779: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-04-13 14:22:09.527388: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2025-04-13 14:22:09.529603: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-04-13 14:22:09.535045: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
/home/eddy/miniconda3/envs/s/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.
  super().__init__(activity_regularizer=activity_regularizer, **kwargs)
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1744546931.179931   44001 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
I0000 00:00:1744546931.201680   44001 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
I0000 00:00:1744546931.201796   44001 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
I0000 00:00:1744546931.202802   44001 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
I0000 00:00:1744546931.202888   44001 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
I0000 00:00:1744546931.202941   44001 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
I0000 00:00:1744546931.253979   44001 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
I0000 00:00:1744546931.254092   44001 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
I0000 00:00:1744546931.254153   44001 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-04-13 14:22:11.254203: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 8861 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070, pci bus id: 0000:01:00.0, compute capability: 8.9
I0000 00:00:1744546932.279444   44091 service.cc:146] XLA service 0x7274a001bd20 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
I0000 00:00:1744546932.279459   44091 service.cc:154]   StreamExecutor device (0): NVIDIA GeForce RTX 4070, Compute Capability 8.9
2025-04-13 14:22:12.293182: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2025-04-13 14:22:12.367365: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 90100
I0000 00:00:1744546933.676441   44091 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. 

Inference execution on 2025-04-13 14:22:31
Command: python /home/eddy/Documents/Agentomics-ML/datasets/competitors/1-shot_llm_agent/gpt4o/inference_1.py --input /home/eddy/Documents/Agentomics-ML/datasets/human_non_tata_promoters/human_nontata_promoters_test.no_label.csv --output /home/eddy/Documents/Agentomics-ML/datasets/competitors/1-shot_llm_agent/gpt4o/predictions.csv
Duration: 3.17 seconds
Return code: 0

STDOUT:

[1m  1/283[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1:14[0m 265ms/step
[1m 58/283[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 881us/step  
[1m109/283[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 940us/step
[1m150/283[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 1ms/step  
[1m189/283[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 1ms/step
[1m283/283[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 1ms/step
[1m283/283[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 1ms/step

STDERR:
2025-04-13 14:22:28.141905: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-04-13 14:22:28.148096: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-04-13 14:22:28.155916: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2025-04-13 14:22:28.158157: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-04-13 14:22:28.163754: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1744546949.414850   45410 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
I0000 00:00:1744546949.436595   45410 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
I0000 00:00:1744546949.436703   45410 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
I0000 00:00:1744546949.437814   45410 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
I0000 00:00:1744546949.437880   45410 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
I0000 00:00:1744546949.437926   45410 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
I0000 00:00:1744546949.474236   45410 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
I0000 00:00:1744546949.474324   45410 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
I0000 00:00:1744546949.474380   45410 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355
2025-04-13 14:22:29.474427: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 8856 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070, pci bus id: 0000:01:00.0, compute capability: 8.9
WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
I0000 00:00:1744546950.006481   45492 service.cc:146] XLA service 0x7f6914004380 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
I0000 00:00:1744546950.006501   45492 service.cc:154]   StreamExecutor device (0): NVIDIA GeForce RTX 4070, Compute Capability 8.9
2025-04-13 14:22:30.010235: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2025-04-13 14:22:30.019542: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 90100
I0000 00:00:1744546950.229465   45492 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.

Evaluation execution on 2025-04-13 14:22:31
Command: python /home/eddy/Documents/Agentomics-ML/src/eval/evaluate_result.py --results /home/eddy/Documents/Agentomics-ML/datasets/competitors/1-shot_llm_agent/gpt4o/predictions.csv --test /home/eddy/Documents/Agentomics-ML/datasets/human_non_tata_promoters/human_nontata_promoters_test.csv --output /home/eddy/Documents/Agentomics-ML/datasets/competitors/1-shot_llm_agent/gpt4o/metrics_run_1.txt
Duration: 0.44 seconds
Return code: 0

STDOUT:

STDERR:
